# 概览

浏览器:是一个软件，用户可使用它访问网络上的一些资源，同时将资源进行渲染，显示出一些漂亮的UI结果，供用户使用

关键点：

1. 网络处理
    1. socket编程
    2. 连接/关闭对端的网络\(TCP/IP\)
    3. DNS解析
    4. 请求应用层的各种资源：图片、脚本文件、多媒体文件、HTML内容、XML内容等
2. 渲染/排版视图
3. 执行脚本，控制渲染、触发事件、控制网络请求
4. 数据存储，cookie 各种缓存 特殊数据
5. 软件自带的用户操作UI界面，如：用户登陆、插件配置、cookie策略等
6. 插件，可以嵌入一些3方写的开源脚本

> 看着东西也不少，分析一下，其实核心是：渲染引擎\+脚本引擎\(js\)

# 渲染引擎（浏览器内核）

1. Trident:IE4启动了它，IE5 IE6 IE7 IE8 IE9 IE10
2. EdgeHTML:在Trident基础之上修改而来，IE11使用

> 感觉是有那么点放弃Trident的意思，但最终EdgeHTML在2018也被微软放弃，之后进入开源领域\(Chromium\)，不再100%自研内核，浏览器也由IE换成了Microsoft Edge，放弃IE

1. Gecko:开源项目，C\+\+编写。FireFox主要使用
2. KHTML:LINUX,
3. WebKit/WebKit2: apple\(chrome早期使用WebKit变异版的Chromium\),开源的项目,其前身是来源于KDE\(KHTML\+KJS\).包含：WebCore JavaScriptCore
4. Chromium:chrome,是WebKit的一个分支
5. Bink:早期chrome Chromium，具说后来慢慢转移到 Bink 上了。在 Chromium 上研发Bink\(渲染引擎\)
6. Presto:Opera前内核,已废弃

> 从微软最终放弃Trident/EdgeHTML来看，开发者可能再也不用去兼容IE/Edge系列了，我们也不用再学习它了。但也是可惜IE最终被微软放弃，一手好版打的希烂
> 
> 
> 另外感觉微软是为了闭源而闭源，还各种不遵守规则：W3C ，造成技术落后、BUG居多、性能不好、软件臃肿操作反人类

## 分析：

从微软也转向开源阵营，最终就剩下3大阵营：

1. Gecko:好像它与 WebKit 对比，略重，但好像升级了一个大版本，感觉未来不如另外2个
2. WebKit:苹果主推
3. Chromium/Bink:google\(chrom\)主推，微软也在向此靠拢

# JS引擎

1. Rhino:Mozilla基金会管理，开放源代码，完全以Java编写。
2. Chakra：ie9开始启用，后续的edge也在使用
    Jscript：ie9以前

> 这两都是微软的产物，但基本都放弃了

1. SpiderMonkey:网景研发
    TraceMonkey：Mozilla研发，算是对SpiderMonkey升级吧
    JaegerMonkey：TraceMonkey升级版

> 这3个严格说都是网景公司产出

1. JavaScriptCore:webkit 内置的JS引擎
2. Nitro:safari主推，好像是在JavaScriptCore基础上优化的
3. linear A/ linear B /futhark/carakan：opera使用

## 分析

Rhino基本没听说，Chakra/Jscript已放弃，linear过于小众，剩下的就3个：

1. TraceMonkey / JaegerMonkey:fireFox主推
2. v8,google主推，且还衍生出nodejs
3. JavaScriptCore / Nitro: apple主推

> 我更看好V8，也可能是各种文档DEMO就用V8做解说，且完全开源

# 主流厂商浏览器

|                      |            |                    |
|----------------------|------------|--------------------|
|IE                    |微软        |                    |
|Edge                  |微软        |                    |
|chrom                 |google      |                    |
|safari                |apple       |                    |
|opera                 |挪威一家公司|好像被国内公司收购了|
|fireFox               |mozila 网景 |                    |
|TT\(Tencent Traveler\)|腾讯        |                    |
|360                   |360         |                    |
|UC                    |            |                    |
|搜狗                  |搜狗        |                    |
|猎豹                  |猎豹        |                    |
|傲游                  |傲游        |                    |

国内的青一色没有自己的内核，除非有特殊功能，如：腾讯的可以绑定微信推送消息，不然我都不看好

> 没核心技术，一但被卡脖挺伤的

国外的，说到底就3个：chrom fireFox safari，日常开发也就这3个，应该这3个才是主流

# 渲染引擎

组成：UI交互、网络通信、解析HTML构建DOM树、解析CSS渲染树、绘制输出、数据存储（缓存、COOKIE）

1. UI交互：打开浏览器后，呈现给用户的界面，像：地址栏、收藏夹、前提/后退等
2. 网络通信：根据用户输入的URL地址，获取数据。如：向DNS地起请求TCP连接请求，获取IP，再根据IP向服务端发起SOCK请求。还有图片、文件等等。
3. 解析HTML构建DOM树：网络通信获取脚本语言代码

DOM树\-》渲染树\-》绘制，其中如果遇到js代码，则会被中断，因为JS可以会插入新的DOM节点，所以会阻塞

渲染树：layout、 paint

遇到'\<'，进入标记阶段，标识当前状态为 标签 模式，接下来a\-z，为关键字名称，遇到'\>'，结果标记阶段，开户数据状态，再次遇到'\<'，再次进入标签阶段，遇到'/'符号，证明进入结束阶段

根据以上解析规则，浏览器，首先会创建document对象（根结点），然后解析，第一个标签为：html,那么再生成HTML对象，插入到DOCUMENT对象中，如果没有找到HEADER标签，浏览器会生成一个header对象，再次插入到document对象，同时浏览器还有容错处理。

CSS，其实是不会改变DOM对象，所以，CSS的解析是完成不会影响到构建树的过程

理论上，网络是同步的，解析器遇到 \<script\> 标记时立即解析并执行脚本，文档的解析将停止，直到脚本执行完毕。如果脚本是外部的，那么解析过程会停止，直到从网络同步抓取资源完成后再继续。

在 DOM 树构建的同时，浏览器还会构建另一个树结构：呈现树，绘制内容

每一个元素，都是一个呈现器，表示成：矩形，区域。它包含诸如宽度、高度和位置等几何信息。 受display影响

但，呈现器和DOM树并非一一对应，如head，他的DISPLAY=none

有一些 DOM 元素对应多个可视化对象。它们往往是具有复杂结构的元素，无法用单一的矩形来描述。例如，“select”元素有 3 个呈现器：一个用于显示区域，一个用于下拉列表框，还有一个用于按钮。如果由于宽度不够，文本无法在一行中显示而分为多行，那么新的行也会作为新的呈现器 而添加

有一些呈现对象对应于 DOM 节点，但在树中所在的位置与 DOM 节点不同。浮动定位和绝对定位的元素就是这样，它们处于正常的流程之外，放置在树中的其他地方，并映射到真正的框架，而放在原位的是占位框架。

遇到 IMG 标签，那么重新发起一次请求

