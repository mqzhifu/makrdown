# 核心模块列表

1. PMG
2. GC/内存分配
3. 编译过程
4. /内存分配
5. 数组/切片
6. MAP/队列
7. 排它锁/读写锁
8. chan
9. context
10. new/make
11. sleep/timer
12. 类/封装/继承/多态/接口
13. error/panic/recover/defer/fatal/return
14. 引用/指针/nil
15. mod包管理
16. tracer compile|pprof
17. 单元测试

## PMG

太长，跳转另一个文章看吧

## 内存分配

## GC

GC定义：遍历内存中的对象引用，找出已经不使用的对象，释放内存。

核心就是：找到无用的内存块。

STW : stop the world

当触发了GC时，即触发STW。用户态的所有执行代码，暂时停止。也好理解：内存有IO并发问题，GC在内存DELETE而用户代码又在执行，那就乱了。

STW就是各类语言在做GC最难的地方，停顿时间的长短就是优化的方向 。

GC的几种算法：引用计数、标记/清除、老旧法\(分代收集\)

GO的GC方法：三色标记法（1.5版本引入）

第一阶段：

1. stop the world
2. 每个processor启动一个mark worker goroutine用于标记（用于第二阶段工作）
3. 启动gc write barrier（记录一下后续在进行marking时被修改的指针）
4. 找到所有roots（stack, heap, global vars）并加入标记队列
5. start the world，进入第二阶段

第二阶段：

1. 从标记队列里面取出对象，标记为黑色（不能GC）
2. 然后检查是否有是指向另一个对象，是，则加入标记队列
3. golang中分配对象会根据是否是指针分别放到不同的span中，根据这个如果span是指针span，那么就需要继续scan下一个对象，否则停止该路scan，取队列中下一个对象继续scan
4. 在扫描过程中，如果用户代码修改对象，那么会触发写屏障，将对象标记为灰色，并加入单独的扫描队列中

第三阶段

1. stop the world
2. 处理marking过程中修改的指针
3. makeing

第四阶段

1. 到这一阶段，所有内存要么是黑色的要么是白色的，清楚所有白色的即可
2. golang的内存管理结构中有一个bitmap区域，其中可以标记是否“黑色”
3. sweep

所以，GO为了减少stop the world 的时间，在第二和第四阶段即会重新开始执行用户态的代码。第一和第三阶段会停止用户代码执行。

GC触发条件

1. 内存大小阈值， 内存达到上次gc后的2倍
2. 达到定时时间 ，2m interval

这里有个小问题：触发条件有点高，第一条的阈值会动态的一直递增，而第2条的时间周期又有点长。

## 数组

跟其它语言都差不多，一个容器，在内存是一段连续的空间。

数组均是值传递：即传参后，函数内部改动数组里的值，外部的数组值不变

数组：

有意思是下面：

1. a \[0\]int
2. b struct{}
3. d \[10\]struct{}
4. e = new\(\[10\]struct{}\)
5. f byte

1\-4的地址均是一样的，5才是真正的内存地址

## 切片 Slices

是引用，可任意更改数组大小，换个角度理解就是：可动态添加/删除数组元素，且是地址引用

## 数组/切片

len:数组的长度

cap:数组可容纳的元素

正常一个数组肯定是定长的~如果想要变长，就得使用slices，它其实也是定长的，区别是他可以在人和的过程，自动将原数组容量放大2倍

总结：感觉切片的模式，是弥补了数组的扩展性，避免了因为定长，而使开发者频繁 的需要手动扩容数组。还可以动态切割数组元素。那么使用的结论就是：数组\+切片配置使用。

# MAP

底层是hash\+map,即：数组\+链表

hash fn:aes hash/memhash

核心结构体：hamp bmap

## hamp:a header for a go map

一个结构体，这里有很多汇总的字段

1. buckets \-\>指向一个数组的字段
2. b 决定创建多少个bucket ,BX2次方，就是放大2倍
3. hash因子

## bmap:a bucket for a Go map

一个bucket集合

注：flags元素，是用来防止并发写的，但是操蛋的点也在这儿，他类似于全局锁，即只要同时有2个协程并发写，你的程序就报pnaic了

concurrent map read

那读写并发呢？一样....

concurrent map read and map write

总结下就是：允许并发读，不允许并发写、并发写读

## 大体转换过程

将KEY转化成一个数字，映射到数组中。

这个数字，包含两部分内容：

1. 低8位指向bmap
2. 高8位指向bmap中的真实的key

翻译下：低8位为hmap中的\(指向\)数组的键值，高8位为数组的bmap中的数组的key值

感觉就是个二级hash结构，一级是汇总数组的结构体，然后指向一个数组，这个数组里的值是hmap\-bucket结构体，而这个bucket结构体里又是一个汇总结构，此结构体里又包含一个数组.

## 流程

1. 创建一个MAP，即会有一个hmap结构体
    hmap结构体进行初始化结构体的元素值
    1. B值，这个是确定有几个bucket = 0
    2. buckets:指针，指向一个数组，这里是新创建一个数组
    3. old\-buckets:指针，指向一个数组，扩容时使用
    4. hash因子
    5. count = 0
    6. flags //处理并发写
    7. 溢出桶的一些信息
2. 此时，有一个元素添加
3. 将该元素的KEY，HASH FUNC \+ has因子 = 转换成一个数字
4. 低8位再转换一个数字，数字范围:0~数组最大长度\-1，即得到数组的key
    准确的说是：低8位与 hmap中的B值做\<与\>运算
5. 此时，创建一个bucket，同时再创建3个数组
    keys values tophash
6. 将真实的KV值，存到这个3个新的数组中
7. 最后，将该bucket放置到第4步中得出K值的数组中
8. 将hmap中的count值\+1

## 查找

1. 将该元素的KEY，HASH FUNC \+ has因子 = 转换成一个数字
2. 根据低8位，与B做与去处，找到该bucket所在数组的索引位置
3. 用高8位循环比对：从该 bucket 结构的元素 tophash 数组中，查找
4. 如果找不到，再去 overflow中找
5. 如果还是找不到，即该KEY不存在

这里的tophash有点意思，不是直接对真的key值比对，而是先找tophash，然后如果找到了，根据索引值，直接去另外两个数组里取值。也算是个取巧吧，对KEY值的搜索优化

## 扩容/链表

触发扩容条件：

1. map中实际存放元素总个数 / bucket \> 6.5
2. overflow bucket 过多
    1. B \<= 15 ，已使用溢出桶个数\>= 2^B
    2. b \> 15 ,已使用溢出桶个数\>= 2^15

溢出扩容：是等量扩容

总个数不够：翻倍扩容

当触发扩容后，会新创建一个数组，且旧数组依然在保存，也就是新/旧两个桶会并行一段时间。如果此时有新的数据过来了，肯定是往新桶里添加。

## 排它锁

两个判断

1. 保底的协程 ：当前时间 减去 一个WS连接最后的更新时间 \> 10s ，即断线
2. 当一个连接建立成功后，我会有一个定时心跳，定时的规则：
    每次都定时的时间都不一样，取决于RTT

第一次，随便取个值：假设1S，1S内正常有响应，计算出RTT，清掉这个RTT

第二次，用上一次的RTT X 2 ，设定一个定时器。如果时间内能收到，重复这个过程 ，如果触发了该定时器，即：认为该连接有问题RTT X 4 ，重复这个过程 ，走到RTT\>=1s~3S\(这里先不定死\)，即连接肯定有问题了，断开该连接，给其它正常的玩家发送有玩家已断线

# sleep/timer

原本觉得这东西没必要写，默认就是SYS CALL 内核。

结果：用pprof查看，发现有大量的 runtime.futex 占CPU

又查了下：好像不简单，GOLANG里的sleep 挺复杂

futex : Fast Userspace muTexes

另外为啥要把timer跟sleep一起讲，因为：sleep 底层是timer实现，好惊讶\!\!\!

## timer

创建一个timer，会创建一个管道，然后把该timer甩到timersBucket\(最小堆（四叉树）\)，既然是小根堆 ，那最上面的肯定是时间 最小的。有个调度器，定时扫描这个堆顶即可

区别

sleep:需要被唤醒，即sleep后立刻交出执行权

timer:走channel模式，阻塞模式

查了下资料，说：sleep 会放弃执行权，也就是放弃G的执行权。也可能会造成放弃M的执行权，简单说就是：会触发线程级睡眠 ，那么GO的调度器就会很麻烦，要来回切换调度，造成过高的耗费资源 ，但归根结底还是使用timer机制，感觉，也没啥本质区别。

## 排它锁

也要互斥锁，每次要操作一个数据时，要先获取该锁，否则等待。拿到锁的人，使用结束后，解锁

也叫自旋锁：当某个协程获取到该锁，其它的协程再想获取该锁，那就得自旋...

从上面分析，一但某协程拿不到该锁，即会阻塞...

```

type Mutex struct {
    state int32
    sema  uint32
}

```

state:当前锁的状态

sema:信号量

state,一个int32

默认=0：未使用

1=mutexLocked:锁定状态

2=mutexWoken:从正常模式被从唤醒

3=mutexStarving: 当前的互斥锁进入饥饿状态

4=waitersCount — 当前互斥锁上等待的 goroutine 个数

lock 加锁

如果状态=0，即一切杂7杂8的状态情况都为假 ，那直接获取，如果一条不行，进入slowLock 函数

waitStartTime 等待开始时间

starving ：是否饥饿

awoke 是否唤醒

iter 自旋次数

然后进入自旋，其实就是个for 死循环，不过挺取巧的。这个函数挂着Mutex引用，这期间如果其它持有协程解锁，这里一并还能判断出来。

但也借用了队列，既然借用了队列，那肯定就不是无脑自旋了。

加入饥饿状态：应该是为了保证一定公平性

加入等待获取锁的协程数变量：可以再次平衡算法

最后：所有等待锁的goroutine按照FIFO顺序等待

死锁:函数1中设定了锁X，将X引用传到函数2中，2中直接锁，不释放，然后return.函数1执行流继续，这个时候，如果函数1想再加锁...阻塞

读写锁

一个资源，可以加读锁或写锁

其中：

如果一个协程加了读锁，另一个协程也可以加读锁，但不能加写锁了

如果一个协程加了写锁，其它协程不能加任何锁了

写锁优先集高于读锁

这种锁，适合读多写少的情况

# context

跳转

# 引用/指针

都是操作内存，内存原理可讲的东西太多，忽略了先。

先说指针，定义一个变量名：PP，类型为指针，同时该指针只能指向int类型的地址

> var pp \*int
> 
> 
> i := 1
> 
> 
> pp = &i

试着输出下：

println\(pp\)

> 0xc00040a008

println\(\*pp\)

> 1

简单理解下：PP是个变量，该变量里保存的是一个地址\(引用\)~直接输出该变量，是一个地址，而加上\*号，即把该地址指向的值输出
